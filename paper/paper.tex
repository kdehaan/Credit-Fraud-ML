\documentclass[10pt,conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subfig}
\usepackage{listings}
\lstset{numbers=left,stepnumber=1,basicstyle=\footnotesize\ttfamily}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\def\code#1{\texttt{#1}}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\begin{document}

\title{Comparing Machine Learning Algorithms for Predicting Cancellation of Hotel Bookings\\}

\author{\IEEEauthorblockN{Kevin de Haan}
  \IEEEauthorblockA{ %\textit{Department of Computing Science} \\
%     \textit{University of Alberta}\\
    Edmonton, Canada\\
  Email: kdehaan@ualberta.ca}
}

\maketitle

\begin{abstract}
 Hotels around the world have dealt with cancellations since their inception. Reservations require that a space be set aside, and cancellations mean that even the most consistently popular vacation destinations are often floating unused rooms and wasted space. Being able to predict whether a customer is likely to cancel ahead of time allows establishments to operate on significantly tighter occupancy margins, improving their efficiency and freeing up more space for customers who will follow through on their plans. The nature of this binary classification problem is well suited to simple machine learning strategies; however, more advanced techniques still have the opportunity to clearly demonstrate their ability.
\end{abstract}

\begin{IEEEkeywords}
  Data Science; Hospitality Industry; Machine Learning; K-nearest Neighbors; Linear SGD; Multi-layer Perceptron; Scikit-learn
\end{IEEEkeywords}


\section{Introduction}
  In the hospitality industry, it is paramount to maximize occupancy rates. Cancellations can have a significant impact on revenue, and to compensate many hotels often sell above their capacity\cite{mehrotra_ruttley_2006}. While this practice is often worthwhile, it can have significant costs in relocation, compensation and reputation. Having the ability to predict the likelihood of cancellation on a case-by-case basis has significant impact on reducing the risk and improving the margins involved with overbooking a hotel or resort\cite{morales2010}. One might expect that the factors leading to cancelling a hotel reservation would extremely complicated, akin to predicting the weather; however, the majority of cancelled bookings are in fact predictable given a relatively small subset of information. Using the hotel booking data set created by Antonio, de Almeida and Nunes\cite{Antonio2019} we will investigate the utility of three off-the-shelf machine learning algorithms for predicting the outcome of a hotel reservation.

\section{Problem Formulation}
  Simply put, the goal of each of the machine learning models used is to take in a set of parameters that can be known before the date of arrival, and make a binary prediction about whether the reservation is going to be cancelled.
  \subsection{The Data}
    The data set used is adapted from one created by Antonio, de Almeida and Nunes\cite{Antonio2019} that has been cleaned and formatted by Mock and Bichat\cite{mock_bichat}. It includes bookings from two locations - a city hotel and a resort hotel. Data columns include the lead time between booking and the date of stay, the date of arrival, the duration of the stay, the volume of adults, children and babies, if the guest is a repeat customer, the number of previous cancellations and amount of special requests made, among others. 66\% of the rows are taken from the city hotel, while the remaining 34\% are from the resort hotel. There are 44224 (37.06\%) examples of cancelled bookings and 75116 (62.94\%) instances where the booking went through, for a total of 11934 rows. Some columns have been altered to preserve anonymity\cite{Antonio2019}.
  
  

\section{Approaches and Baselines}
  For the purposes of this experiment, three machine learning approaches will be evaluated:
  \begin{itemize}
    \item \textbf{\emph{k}-nearest Neighbors} (KNN) 
    \item A \textbf{Linear Classifier} trained using \textbf{Stochastic Gradient Descent} (SGD)
    \item A \textbf{Multi-layer Perceptron} (MLP)
  \end{itemize}
  In addition to the machine learning techniques employed, a baseline must be established. As this is a \emph{k}-category classification problem, each approach will be compared to two naive baseline predictors:
  \begin{itemize}
    \item \textbf{Majority Guess} will always predict that a booking will not be cancelled.
    \item \textbf{Uniform Random Guess} will predict each possible classification category (i.e, cancelled and not cancelled) at an equal rate.
  \end{itemize}

\section{Evaluating Performance}
 While the relatively low class imbalance of this binary classification problem means that raw accuracy is still meaningful, it is still preferable to find a different metric to better represent the trade-off between precision and recall. Towards this end, the models are evaluated primarily using the \emph{Area Under the Receiver Operating Characteristic Curve} (ROC AUC), a tool used specifically for determining the predictive ability of a binary classifier as the threshold between precision and recall is varied\cite{Fawcett2006}. For this metric, a perfect score is 1 while the worst possible score is 0.5 (this is because in a binary classifier, being 0\% correct is equivalent to being 100\% correct). In addition to the ROC AUC, the \emph{f\textsubscript{1}} score\cite{rijsbergen_1995} and raw accuracy are also included in the event that the reader is more comfortable with their relative values.
 
 Note that both of the naive predictors (\emph{majority guess} and \emph{uniform random guess}) will produce an ROC AUC score of very nearly 0.5, and an \emph{f\textsubscript{1}} score of 
\section{Results}

% \begin{figure}
%   \includegraphics[width=0.5\textwidth]{figures/}
%   \label{}
% \end{figure}

\section{Conclusion}

\nocite{*}
\bibliography{bibs/refs}
\bibliographystyle{IEEEtran}


\vspace{12pt}

\end{document}