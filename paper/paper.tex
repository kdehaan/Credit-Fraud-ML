\documentclass[10pt,conference]{IEEEtran}
\IEEEoverridecommandlockouts

\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{subfig}
\usepackage{listings}
\lstset{numbers=left,stepnumber=1,basicstyle=\footnotesize\ttfamily}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\def\code#1{\texttt{#1}}

\makeatletter
\def\endthebibliography{%
  \def\@noitemerr{\@latex@warning{Empty `thebibliography' environment}}%
  \endlist
}
\makeatother

\begin{document}

\title{Comparing Machine Learning Algorithms for Predicting Cancellation of Hotel Bookings\\}

\author{\IEEEauthorblockN{Kevin de Haan}
  \IEEEauthorblockA{ %\textit{Department of Computing Science} \\
%     \textit{University of Alberta}\\
    Edmonton, Canada\\
  Email: kdehaan@ualberta.ca}
}

\maketitle

\begin{abstract}
 Hotels around the world have dealt with cancellations since their inception. Reservations require that a space be set aside, and cancellations mean that even the most consistently popular vacation destinations are often floating unused rooms and wasted space. Being able to predict whether a customer is likely to cancel ahead of time allows establishments to operate on significantly tighter occupancy margins, improving their efficiency and freeing up more space for customers who will follow through on their plans. The nature of this binary classification problem is well suited to simple machine learning strategies; however, more advanced techniques still have the opportunity to clearly demonstrate their ability.
\end{abstract}

\begin{IEEEkeywords}
  Machine Learning; Hotel Booking Cancellation; K-nearest Neighbors; Linear SGD; Multi-layer Perceptron; Scikit-learn
\end{IEEEkeywords}


\section{Introduction}
 
% \begin{itemize}
%   \item 
%   \item 
%   \item 
% \end{itemize}


\section{Problem Formulation}
  \subsection{Input and Output}
  \subsection{The Data}

\section{Approaches and Baselines}
  For the purposes of this experiment, three machine learning approaches will be evaluated:
  \begin{itemize}
    \item \textbf{\emph{k}-nearest Neighbors} (KNN) 
    \item A \textbf{Linear Classifier} trained using \textbf{Stochastic Gradient Descent} (SGD)
    \item A \textbf{Multi-layer Perceptron} (MLP)
  \end{itemize}
  In addition to the machine learning techniques employed, a baseline must be established. As this is a \emph{k}-category classification problem, each approach will be compared to two naive baseline predictors:
  \begin{itemize}
    \item \textbf{Majority Guess} will always predict that a booking will not be cancelled.
    \item \textbf{Uniform Random Guess} will predict each possible classification category (i.e, cancelled and not cancelled) at an equal rate.
  \end{itemize}

\section{Evaluating Performance}
  Because of the significant class imbalance ratio, evaluating the performance of the different predictors will be performed using the \emph{Area Under the Precision-Recall Curve} (AUPRC)
\section{Results}

% \begin{figure}
%   \includegraphics[width=0.5\textwidth]{figures/}
%   \label{}
% \end{figure}

\section{Conclusion}

\nocite{*}
\bibliography{bibs/refs}
\bibliographystyle{IEEEtran}


\vspace{12pt}

\end{document}